{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D,MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  category\n",
       "0         0        77\n",
       "1         1        81\n",
       "2         2        52\n",
       "3         3        72\n",
       "4         4        58"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/kaggle/input/flower-recognition-he/he_challenge_data/data/train.csv\")\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "train_path='/kaggle/input/flower-recognition-he/he_challenge_data/data/train/'\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "IMG_SIZE = 250\n",
    "for i in range(len(df.image_id)):\n",
    "    img=cv2.imread(train_path+str(df.image_id[i])+'.jpg')\n",
    "    img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "    x.append(img)\n",
    "    y.append(df.category[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "z=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "z = to_categorical(z,102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(z.shape)\n",
    "print(type(x))\n",
    "print(type(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,z,test_size=0.2,random_state=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2,random_state=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(250, 250,..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 248, 248, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 124, 124, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 122, 122, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 61, 61, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 59, 59, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 4, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16384)             67125248  \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 102)               1671270   \n",
      "=================================================================\n",
      "Total params: 92,447,462\n",
      "Trainable params: 92,442,982\n",
      "Non-trainable params: 4,480\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=4096)`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16384)`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=102)`\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "# 1st Convolutional Layer\n",
    "classifier.add(Convolution2D(64,3,3,input_shape=(IMG_SIZE,IMG_SIZE,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.20))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "classifier.add(Convolution2D(128,3,3,activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.30))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "classifier.add(Convolution2D(256,3,3,activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.30))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "classifier.add(Convolution2D(256,3,3,activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.30))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "classifier.add(Convolution2D(512,3,3,activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.30))\n",
    "\n",
    "# 6th Convolutional Layer\n",
    "classifier.add(Convolution2D(1024,3,3,activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.30))\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "#1ST Fully connected layer\n",
    "classifier.add(Dense(output_dim=4096,activation='relu'))\n",
    "classifier.add(Dropout(0.30))\n",
    "classifier.add(Dense(output_dim=16384,activation='relu'))\n",
    "classifier.add(Dropout(0.30))\n",
    "#output layer\n",
    "classifier.add(Dense(output_dim=102,activation='softmax'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch = 50 \n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    rotation_range=60,  # randomly rotate images in the range (60, 0 to 180)\n",
    "    zoom_range = 0.2, # Randomly zoom image \n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode = \"reflect\"\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = classifier.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n",
    "                              epochs= epoch,validation_data=(x_test,y_test),\n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14832 samples, validate on 3708 samples\n",
      "Epoch 1/100\n",
      "14832/14832 [==============================] - 71s 5ms/step - loss: 6.1717 - acc: 0.0340 - val_loss: 4.5651 - val_acc: 0.0426\n",
      "Epoch 2/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 4.5641 - acc: 0.0568 - val_loss: 4.8385 - val_acc: 0.0628\n",
      "Epoch 3/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 3.9889 - acc: 0.1069 - val_loss: 3.8566 - val_acc: 0.1303\n",
      "Epoch 4/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 3.7089 - acc: 0.1456 - val_loss: 3.7191 - val_acc: 0.1400\n",
      "Epoch 5/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 3.4107 - acc: 0.1866 - val_loss: 2.9938 - val_acc: 0.2082\n",
      "Epoch 6/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 3.2581 - acc: 0.2166 - val_loss: 4.2855 - val_acc: 0.0992\n",
      "Epoch 7/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 3.1807 - acc: 0.2329 - val_loss: 3.1656 - val_acc: 0.2147\n",
      "Epoch 8/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.9635 - acc: 0.2635 - val_loss: 3.4747 - val_acc: 0.2015\n",
      "Epoch 9/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.7650 - acc: 0.3033 - val_loss: 2.7592 - val_acc: 0.2740\n",
      "Epoch 10/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.5385 - acc: 0.3452 - val_loss: 2.1936 - val_acc: 0.3724\n",
      "Epoch 11/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.3939 - acc: 0.3777 - val_loss: 2.1749 - val_acc: 0.3843\n",
      "Epoch 12/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.2563 - acc: 0.4117 - val_loss: 1.9286 - val_acc: 0.4782\n",
      "Epoch 13/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.4678 - acc: 0.3978 - val_loss: 3.4739 - val_acc: 0.2764\n",
      "Epoch 14/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.3146 - acc: 0.4200 - val_loss: 1.9931 - val_acc: 0.4347\n",
      "Epoch 15/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.2484 - acc: 0.4461 - val_loss: 13.2359 - val_acc: 0.0197\n",
      "Epoch 16/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 2.2796 - acc: 0.4226 - val_loss: 2.5045 - val_acc: 0.3498\n",
      "Epoch 17/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.9076 - acc: 0.4708 - val_loss: 1.6101 - val_acc: 0.5431\n",
      "Epoch 18/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.7172 - acc: 0.5143 - val_loss: 1.7239 - val_acc: 0.5170\n",
      "Epoch 19/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.5301 - acc: 0.5552 - val_loss: 1.4071 - val_acc: 0.6060\n",
      "Epoch 20/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.4979 - acc: 0.5705 - val_loss: 1.3502 - val_acc: 0.6122\n",
      "Epoch 21/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.3754 - acc: 0.6013 - val_loss: 1.3657 - val_acc: 0.6028\n",
      "Epoch 22/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.2716 - acc: 0.6308 - val_loss: 1.2314 - val_acc: 0.6394\n",
      "Epoch 23/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.2188 - acc: 0.6467 - val_loss: 1.1721 - val_acc: 0.6607\n",
      "Epoch 24/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.1334 - acc: 0.6672 - val_loss: 1.2215 - val_acc: 0.6448\n",
      "Epoch 25/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.0766 - acc: 0.6868 - val_loss: 1.0449 - val_acc: 0.6990\n",
      "Epoch 26/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 1.0261 - acc: 0.6998 - val_loss: 1.2401 - val_acc: 0.6432\n",
      "Epoch 27/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.9778 - acc: 0.7148 - val_loss: 1.1002 - val_acc: 0.6761\n",
      "Epoch 28/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.8899 - acc: 0.7370 - val_loss: 0.9211 - val_acc: 0.7430\n",
      "Epoch 29/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.8426 - acc: 0.7519 - val_loss: 0.9545 - val_acc: 0.7201\n",
      "Epoch 30/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.7934 - acc: 0.7676 - val_loss: 0.7658 - val_acc: 0.7845\n",
      "Epoch 31/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.7521 - acc: 0.7775 - val_loss: 1.1372 - val_acc: 0.6996\n",
      "Epoch 32/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.7132 - acc: 0.7916 - val_loss: 0.7486 - val_acc: 0.7802\n",
      "Epoch 33/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.6993 - acc: 0.7965 - val_loss: 0.9597 - val_acc: 0.7206\n",
      "Epoch 34/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.6557 - acc: 0.8070 - val_loss: 0.8598 - val_acc: 0.7597\n",
      "Epoch 35/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.6409 - acc: 0.8161 - val_loss: 0.6434 - val_acc: 0.8136\n",
      "Epoch 36/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.5986 - acc: 0.8244 - val_loss: 0.7921 - val_acc: 0.7789\n",
      "Epoch 37/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.5636 - acc: 0.8354 - val_loss: 0.7175 - val_acc: 0.8020\n",
      "Epoch 38/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.5686 - acc: 0.8364 - val_loss: 0.6938 - val_acc: 0.8020\n",
      "Epoch 39/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.5399 - acc: 0.8462 - val_loss: 0.6761 - val_acc: 0.8093\n",
      "Epoch 40/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.5118 - acc: 0.8528 - val_loss: 0.8342 - val_acc: 0.7775\n",
      "Epoch 41/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.5023 - acc: 0.8561 - val_loss: 0.6119 - val_acc: 0.8376\n",
      "Epoch 42/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.4513 - acc: 0.8682 - val_loss: 0.6093 - val_acc: 0.8420\n",
      "Epoch 43/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.4352 - acc: 0.8761 - val_loss: 0.6759 - val_acc: 0.8198\n",
      "Epoch 44/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.4055 - acc: 0.8828 - val_loss: 1.2497 - val_acc: 0.6974\n",
      "Epoch 45/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.4006 - acc: 0.8865 - val_loss: 0.7095 - val_acc: 0.8112\n",
      "Epoch 46/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.4006 - acc: 0.8863 - val_loss: 1.1288 - val_acc: 0.7381\n",
      "Epoch 47/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3729 - acc: 0.8968 - val_loss: 0.9158 - val_acc: 0.7662\n",
      "Epoch 48/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3784 - acc: 0.8982 - val_loss: 0.8455 - val_acc: 0.7891\n",
      "Epoch 49/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3624 - acc: 0.8996 - val_loss: 0.7761 - val_acc: 0.7915\n",
      "Epoch 50/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3547 - acc: 0.9012 - val_loss: 0.5062 - val_acc: 0.8681\n",
      "Epoch 51/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3693 - acc: 0.8952 - val_loss: 0.5873 - val_acc: 0.8492\n",
      "Epoch 52/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3392 - acc: 0.9062 - val_loss: 0.5999 - val_acc: 0.8487\n",
      "Epoch 53/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3193 - acc: 0.9140 - val_loss: 0.6013 - val_acc: 0.8587\n",
      "Epoch 54/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3424 - acc: 0.9071 - val_loss: 0.9214 - val_acc: 0.7678\n",
      "Epoch 55/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3100 - acc: 0.9175 - val_loss: 0.7059 - val_acc: 0.8255\n",
      "Epoch 56/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2901 - acc: 0.9206 - val_loss: 0.8261 - val_acc: 0.8077\n",
      "Epoch 57/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.3164 - acc: 0.9159 - val_loss: 0.7873 - val_acc: 0.8163\n",
      "Epoch 58/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2810 - acc: 0.9231 - val_loss: 0.5178 - val_acc: 0.8865\n",
      "Epoch 59/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2969 - acc: 0.9212 - val_loss: 0.6481 - val_acc: 0.8430\n",
      "Epoch 60/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2746 - acc: 0.9250 - val_loss: 0.6744 - val_acc: 0.8352\n",
      "Epoch 61/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2914 - acc: 0.9261 - val_loss: 0.7599 - val_acc: 0.8112\n",
      "Epoch 62/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2917 - acc: 0.9246 - val_loss: 0.5534 - val_acc: 0.8716\n",
      "Epoch 63/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2757 - acc: 0.9282 - val_loss: 0.6784 - val_acc: 0.8409\n",
      "Epoch 64/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2613 - acc: 0.9295 - val_loss: 0.5691 - val_acc: 0.8665\n",
      "Epoch 65/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2413 - acc: 0.9357 - val_loss: 0.5214 - val_acc: 0.8746\n",
      "Epoch 66/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2534 - acc: 0.9333 - val_loss: 0.7060 - val_acc: 0.8409\n",
      "Epoch 67/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2566 - acc: 0.9361 - val_loss: 0.6672 - val_acc: 0.8544\n",
      "Epoch 68/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2657 - acc: 0.9343 - val_loss: 1.5513 - val_acc: 0.7114\n",
      "Epoch 69/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2460 - acc: 0.9395 - val_loss: 0.4956 - val_acc: 0.8746\n",
      "Epoch 70/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2368 - acc: 0.9367 - val_loss: 0.5973 - val_acc: 0.8638\n",
      "Epoch 71/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2569 - acc: 0.9354 - val_loss: 0.5608 - val_acc: 0.8692\n",
      "Epoch 72/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2407 - acc: 0.9384 - val_loss: 0.5134 - val_acc: 0.8846\n",
      "Epoch 73/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2521 - acc: 0.9366 - val_loss: 0.7829 - val_acc: 0.8147\n",
      "Epoch 74/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2994 - acc: 0.9285 - val_loss: 0.5371 - val_acc: 0.8813\n",
      "Epoch 75/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2318 - acc: 0.9405 - val_loss: 0.9447 - val_acc: 0.7875\n",
      "Epoch 76/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2970 - acc: 0.9304 - val_loss: 0.7112 - val_acc: 0.8503\n",
      "Epoch 77/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2647 - acc: 0.9368 - val_loss: 0.6451 - val_acc: 0.8614\n",
      "Epoch 78/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2687 - acc: 0.9324 - val_loss: 0.6441 - val_acc: 0.8617\n",
      "Epoch 79/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2446 - acc: 0.9431 - val_loss: 0.6818 - val_acc: 0.8557\n",
      "Epoch 80/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2271 - acc: 0.9440 - val_loss: 1.4092 - val_acc: 0.7139\n",
      "Epoch 81/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2253 - acc: 0.9459 - val_loss: 0.8448 - val_acc: 0.8161\n",
      "Epoch 82/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2039 - acc: 0.9517 - val_loss: 0.6891 - val_acc: 0.8492\n",
      "Epoch 83/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1940 - acc: 0.9507 - val_loss: 0.6476 - val_acc: 0.8730\n",
      "Epoch 84/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2056 - acc: 0.9512 - val_loss: 0.7051 - val_acc: 0.8533\n",
      "Epoch 85/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1894 - acc: 0.9506 - val_loss: 0.5865 - val_acc: 0.8857\n",
      "Epoch 86/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1720 - acc: 0.9570 - val_loss: 0.6989 - val_acc: 0.8490\n",
      "Epoch 87/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1934 - acc: 0.9529 - val_loss: 0.5640 - val_acc: 0.8824\n",
      "Epoch 88/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1841 - acc: 0.9537 - val_loss: 1.0273 - val_acc: 0.8158\n",
      "Epoch 89/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1937 - acc: 0.9535 - val_loss: 0.4807 - val_acc: 0.9024\n",
      "Epoch 90/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2202 - acc: 0.9516 - val_loss: 0.8110 - val_acc: 0.8492\n",
      "Epoch 91/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2032 - acc: 0.9544 - val_loss: 0.7691 - val_acc: 0.8522\n",
      "Epoch 92/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2382 - acc: 0.9465 - val_loss: 0.8183 - val_acc: 0.8333\n",
      "Epoch 93/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.2062 - acc: 0.9527 - val_loss: 0.5050 - val_acc: 0.8986\n",
      "Epoch 94/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1655 - acc: 0.9610 - val_loss: 0.4838 - val_acc: 0.8956\n",
      "Epoch 95/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1714 - acc: 0.9572 - val_loss: 0.6021 - val_acc: 0.8803\n",
      "Epoch 96/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1793 - acc: 0.9589 - val_loss: 0.8896 - val_acc: 0.8347\n",
      "Epoch 97/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1758 - acc: 0.9606 - val_loss: 0.5264 - val_acc: 0.8991\n",
      "Epoch 98/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1924 - acc: 0.9542 - val_loss: 0.4789 - val_acc: 0.8940\n",
      "Epoch 99/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1808 - acc: 0.9588 - val_loss: 0.6341 - val_acc: 0.8827\n",
      "Epoch 100/100\n",
      "14832/14832 [==============================] - 61s 4ms/step - loss: 0.1900 - acc: 0.9555 - val_loss: 0.8639 - val_acc: 0.8406\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(x_train,y_train,epochs=100,batch_size=128,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18541</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18542</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18543</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18544</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  category\n",
       "0     18540       NaN\n",
       "1     18541       NaN\n",
       "2     18542       NaN\n",
       "3     18543       NaN\n",
       "4     18544       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation=pd.read_csv('/kaggle/input/flower-recognition-he/he_challenge_data/data/test.csv')\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id=[]\n",
    "test_pred=[]\n",
    "\n",
    "for i in validation.image_id:\n",
    "    img=cv2.resize(cv2.imread('/kaggle/input/flower-recognition-he/he_challenge_data/data/test/'+str(i)+'.jpg'),(IMG_SIZE,IMG_SIZE))\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    test_id.append(i)\n",
    "    test_pred.append(int(classifier.predict_classes(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18541</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18542</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18543</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18544</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  category\n",
       "0     18540         2\n",
       "1     18541        94\n",
       "2     18542        38\n",
       "3     18543        71\n",
       "4     18544        71"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission=pd.DataFrame({'image_id':test_id,'category':test_pred})\n",
    "final_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a download=\"subm.csv\" href=\"data:text/csv;base64,image_id,category
18540,2
18541,94
18542,38
18543,71
18544,71
18545,39
18546,69
18547,55
18548,2
18549,88
18550,62
18551,85
18552,88
18553,62
18554,50
18555,81
18556,9
18557,9
18558,50
18559,79
18560,84
18561,94
18562,23
18563,92
18564,85
18565,27
18566,84
18567,77
18568,2
18569,56
18570,73
18571,6
18572,36
18573,36
18574,73
18575,91
18576,26
18577,46
18578,77
18579,2
18580,51
18581,20
18582,73
18583,88
18584,51
18585,65
18586,101
18587,94
18588,93
18589,65
18590,50
18591,87
18592,64
18593,69
18594,16
18595,87
18596,47
18597,7
18598,45
18599,24
18600,89
18601,74
18602,48
18603,45
18604,8
18605,44
18606,45
18607,67
18608,45
18609,82
18610,59
18611,93
18612,22
18613,15
18614,1
18615,22
18616,94
18617,1
18618,59
18619,59
18620,72
18621,77
18622,45
18623,2
18624,8
18625,94
18626,48
18627,24
18628,45
18629,74
18630,41
18631,38
18632,90
18633,64
18634,64
18635,94
18636,76
18637,69
18638,42
18639,79
18640,65
18641,93
18642,50
18643,101
18644,65
18645,51
18646,88
18647,71
18648,87
18649,20
18650,51
18651,77
18652,15
18653,23
18654,73
18655,36
18656,91
18657,56
18658,74
18659,36
18660,50
18661,73
18662,11
18663,50
18664,87
18665,42
18666,87
18667,100
18668,74
18669,41
18670,9
18671,88
18672,88
18673,9
18674,86
18675,15
18676,62
18677,85
18678,47
18679,66
18680,39
18681,71
18682,50
18683,73
18684,93
18685,75
18686,39
18687,67
18688,39
18689,76
18690,68
18691,8
18692,76
18693,24
18694,57
18695,76
18696,55
18697,80
18698,100
18699,69
18700,69
18701,71
18702,57
18703,85
18704,88
18705,9
18706,41
18707,41
18708,88
18709,42
18710,71
18711,11
18712,11
18713,94
18714,61
18715,87
18716,91
18717,42
18718,36
18719,45
18720,57
18721,36
18722,56
18723,48
18724,47
18725,93
18726,51
18727,51
18728,2
18729,54
18730,81
18731,65
18732,65
18733,15
18734,93
18735,45
18736,79
18737,6
18738,90
18739,75
18740,69
18741,87
18742,64
18743,80
18744,48
18745,73
18746,47
18747,50
18748,74
18749,45
18750,24
18751,99
18752,44
18753,45
18754,73
18755,67
18756,59
18757,1
18758,75
18759,9
18760,74
18761,73
18762,59
18763,74
18764,59
18765,95
18766,1
18767,59
18768,22
18769,81
18770,8
18771,45
18772,47
18773,99
18774,94
18775,50
18776,22
18777,82
18778,24
18779,45
18780,80
18781,73
18782,80
18783,94
18784,69
18785,64
18786,82
18787,64
18788,94
18789,40
18790,88
18791,45
18792,93
18793,47
18794,65
18795,65
18796,10
18797,20
18798,51
18799,92
18800,59
18801,51
18802,46
18803,74
18804,36
18805,15
18806,56
18807,73
18808,37
18809,85
18810,36
18811,75
18812,84
18813,61
18814,51
18815,11
18816,2
18817,9
18818,41
18819,47
18820,88
18821,41
18822,9
18823,66
18824,50
18825,57
18826,30
18827,79
18828,80
18829,57
18830,76
18831,75
18832,57
18833,24
18834,76
18835,95
18836,97
18837,14
18838,43
18839,52
18840,57
18841,94
18842,76
18843,80
18844,50
18845,82
18846,57
18847,9
18848,88
18849,69
18850,15
18851,99
18852,36
18853,73
18854,91
18855,36
18856,56
18857,73
18858,41
18859,36
18860,11
18861,61
18862,77
18863,75
18864,40
18865,74
18866,46
18867,42
18868,47
18869,3
18870,93
18871,101
18872,51
18873,93
18874,86
18875,51
18876,69
18877,50
18878,64
18879,90
18880,64
18881,69
18882,73
18883,79
18884,44
18885,45
18886,48
18887,22
18888,73
18889,47
18890,24
18891,80
18892,100
18893,19
18894,81
18895,22
18896,64
18897,1
18898,72
18899,77
18900,59
18901,81
18902,67
18903,45
18904,45
18905,67
18906,45
18907,67
18908,97
18909,45
18910,15
18911,95
18912,81
18913,22
18914,39
18915,96
18916,1
18917,59
18918,72
18919,24
18920,47
18921,74
18922,15
18923,87
18924,22
18925,35
18926,44
18927,45
18928,87
18929,88
18930,64
18931,94
18932,69
18933,30
18934,90
18935,64
18936,92
18937,93
18938,69
18939,51
18940,51
18941,42
18942,10
18943,65
18944,47
18945,65
18946,79
18947,93
18948,46
18949,77
18950,100
18951,71
18952,47
18953,75
18954,11
18955,2
18956,61
18957,56
18958,94
18959,36
18960,11
18961,73
18962,73
18963,36
18964,91
18965,99
18966,88
18967,41
18968,9
18969,47
18970,57
18971,50
18972,39
18973,72
18974,76
18975,91
18976,47
18977,87
18978,57
18979,73
18980,55
18981,76
18982,97
18983,55
18984,71
18985,57
18986,1
18987,41
18988,88
18989,47
18990,62
18991,99
18992,88
18993,73
18994,21
18995,56
18996,81
18997,91
18998,75
18999,76
19000,24
19001,11
19002,73
19003,84
19004,86
19005,73
19006,11
19007,73
19008,77
19009,73
19010,2
19011,45
19012,93
19013,45
19014,37
19015,65
19016,51
19017,20
19018,67
19019,79
19020,51
19021,48
19022,89
19023,64
19024,64
19025,87
19026,94
19027,74
19028,16
19029,34
19030,79
19031,52
19032,74
19033,15
19034,24
19035,45
19036,6
19037,4
19038,81
19039,96
19040,59
19041,1
19042,59
19043,1
19044,95
19045,81
19046,50
19047,24
19048,45
19049,45
19050,67
19051,59
19052,45
19053,67
19054,67
19055,45
19056,89
19057,1
19058,59
19059,78
19060,50
19061,81
19062,1
19063,59
19064,40
19065,45
19066,10
19067,50
19068,10
19069,73
19070,24
19071,45
19072,10
19073,34
19074,50
19075,64
19076,16
19077,77
19078,94
19079,87
19080,80
19081,64
19082,51
19083,90
19084,51
19085,96
19086,65
19087,93
19088,51
19089,93
19090,73
19091,73
19092,73
19093,77
19094,11
19095,2
19096,73
19097,37
19098,75
19099,86
19100,84
19101,91
19102,65
19103,36
19104,75
19105,36
19106,73
19107,56
19108,82
19109,99
19110,88
19111,62
19112,41
19113,88
19114,39
19115,57
19116,24
19117,71
19118,50
19119,66
19120,76
19121,97
19122,49
19123,76
19124,50
19125,79
19126,40
19127,49
19128,8
19129,73
19130,101
19131,15
19132,57
19133,64
19134,76
19135,50
19136,97
19137,37
19138,98
19139,25
19140,7
19141,57
19142,54
19143,63
19144,75
19145,72
19146,25
19147,78
19148,87
19149,87
19150,28
19151,82
19152,10
19153,87
19154,95
19155,23
19156,40
19157,72
19158,82
19159,40
19160,42
19161,78
19162,45
19163,27
19164,10
19165,45
19166,50
19167,82
19168,94
19169,72
19170,72
19171,63
19172,31
19173,55
19174,63
19175,55
19176,12
19177,58
19178,55
19179,35
19180,40
19181,50
19182,59
19183,37
19184,64
19185,9
19186,70
19187,68
19188,35
19189,55
19190,12
19191,12
19192,58
19193,55
19194,95
19195,55
19196,87
19197,63
19198,48
19199,40
19200,72
19201,59
19202,50
19203,80
19204,8
19205,45
19206,74
19207,40
19208,47
19209,24
19210,87
19211,72
19212,72
19213,40
19214,10
19215,73
19216,73
19217,87
19218,28
19219,87
19220,82
19221,87
19222,21
19223,10
19224,91
19225,74
19226,15
19227,63
19228,54
19229,45
19230,70
19231,7
19232,7
19233,25
19234,21
19235,18
19236,50
19237,76
19238,87
19239,4
19240,57
19241,88
19242,57
19243,17
19244,35
19245,50
19246,40
19247,49
19248,11
19249,49
19250,37
19251,49
19252,32
19253,95
19254,54
19255,45
19256,88
19257,94
19258,24
19259,41
19260,43
19261,54
19262,63
19263,40
19264,54
19265,45
19266,63
19267,87
19268,95
19269,85
19270,77
19271,10
19272,87
19273,61
19274,40
19275,40
19276,63
19277,50
19278,72
19279,68
19280,19
19281,13
19282,95
19283,45
19284,27
19285,72
19286,50
19287,94
19288,2
19289,50
19290,77
19291,33
19292,3
19293,55
19294,93
19295,55
19296,31
19297,94
19298,12
19299,68
19300,49
19301,98
19302,59
19303,11
19304,59
19305,98
19306,68
19307,58
19308,12
19309,12
19310,58
19311,55
19312,43
19313,29
19314,55
19315,96
19316,42
19317,29
19318,18
19319,50
19320,50
19321,72
19322,86
19323,27
19324,80
19325,72
19326,14
19327,13
19328,6
19329,96
19330,6
19331,50
19332,35
19333,40
19334,95
19335,87
19336,89
19337,77
19338,87
19339,10
19340,77
19341,50
19342,91
19343,83
19344,37
19345,85
19346,56
19347,63
19348,54
19349,98
19350,7
19351,37
19352,15
19353,57
19354,52
19355,18
19356,50
19357,32
19358,11
19359,49
19360,39
19361,76
19362,50
19363,97
19364,87
19365,50
19366,47
19367,76
19368,38
19369,49
19370,49
19371,89
19372,2
19373,45
19374,7
19375,37
19376,56
19377,82
19378,76
19379,16
19380,91
19381,54
19382,53
19383,63
19384,87
19385,49
19386,78
19387,87
19388,77
19389,62
19390,41
19391,27
19392,13
19393,79
19394,55
19395,83
19396,14
19397,72
19398,33
19399,90
19400,43
19401,15
19402,96
19403,58
19404,58
19405,55
19406,60
19407,55
19408,91
19409,59
19410,37
19411,50
19412,50
19413,50
19414,50
19415,59
19416,22
19417,5
19418,29
19419,4
19420,55
19421,55
19422,12
19423,58
19424,58
19425,72
19426,83
19427,41
19428,90
19429,72
19430,40
19431,40
19432,83
19433,45
19434,13
19435,93
19436,4
19437,79
19438,78
19439,77
19440,72
19441,49
19442,77
19443,63
19444,53
19445,32
19446,56
19447,36
19448,97
19449,73
19450,37
19451,7
19452,71
19453,89
19454,7
19455,49
19456,91
19457,49
19458,92
19459,3
19460,4
19461,50
19462,73
19463,50
19464,87
19465,76
19466,47
19467,42
19468,17
19469,46
19470,42
19471,50
19472,49
19473,49
19474,76
19475,25
19476,41
19477,42
19478,7
19479,22
19480,47
19481,94
19482,21
19483,87
19484,56
19485,63
19486,6
19487,54
19488,87
19489,28
19490,87
19491,26
19492,87
19493,82
19494,15
19495,27
19496,68
19497,47
19498,10
19499,40
19500,82
19501,27
19502,83
19503,49
19504,90
19505,72
19506,75
19507,73
19508,58
19509,87
19510,60
19511,94
19512,55
19513,55
19514,37
19515,70
19516,50
19517,50
19518,46
19519,37
19520,55
19521,55
19522,12
19523,58
19524,94
19525,58
19526,60
19527,72
19528,87
19529,33
19530,45
19531,58
19532,48
19533,73
19534,40
19535,27
19536,45
19537,50
19538,93
19539,79
19540,27
19541,52
19542,87
19543,14
19544,87
19545,73
19546,54
19547,50
19548,36
19549,21
19550,90
19551,56
19552,64
19553,22
19554,7
19555,4
19556,7
19557,43
19558,49
19559,93
19560,49
19561,50
19562,42
19563,47
19564,95
19565,4
19566,76
19567,55
19568,3
19569,76
19570,12
19571,40
19572,76
19573,82
19574,3
19575,92
19576,49
19577,97
19578,22
19579,82
19580,57
19581,89
19582,40
19583,54
19584,36
19585,71
19586,56
19587,74
19588,14
19589,90
19590,53
19591,97
19592,91
19593,19
19594,86
19595,28
19596,76
19597,15
19598,87
19599,83
19600,80
19601,13
19602,52
19603,40
19604,67
19605,77
19606,95
19607,82
19608,10
19609,27
19610,16
19611,72
19612,60
19613,35
19614,43
19615,29
19616,33
19617,84
19618,55
19619,79
19620,7
19621,5
19622,70
19623,94
19624,70
19625,68
19626,6
19627,68
19628,88
19629,70
19630,98
19631,26
19632,95
19633,5
19634,7
19635,90
19636,71
19637,35
19638,60
19639,79
19640,16
19641,2
19642,82
19643,72
19644,24
19645,84
19646,79
19647,25
19648,45
19649,95
19650,3
19651,13
19652,74
19653,35
19654,87
19655,77
19656,1
19657,92
19658,13
19659,87
19660,73
19661,47
19662,6
19663,53
19664,15
19665,87
19666,87
19667,21
19668,79
19669,56
19670,89
19671,73
19672,40
19673,89
19674,87
19675,87
19676,97
19677,50
19678,76
19679,31
19680,90
19681,76
19682,91
19683,76
19684,32
19685,34
19686,95
19687,88
19688,19
19689,4
19690,97
19691,46
19692,85
19693,88
19694,73
19695,15
19696,42
19697,14
19698,53
19699,6
19700,28
19701,76
19702,77
19703,77
19704,23
19705,28
19706,87
19707,80
19708,36
19709,38
19710,0
19711,27
19712,72
19713,47
19714,10
19715,82
19716,73
19717,16
19718,63
19719,72
19720,60
19721,58
19722,25
19723,50
19724,55
19725,60
19726,23
19727,101
19728,95
19729,93
19730,50
19731,79
19732,5
19733,70
19734,41
19735,70
19736,68
19737,70
19738,37
19739,70
19740,31
19741,20
19742,90
19743,1
19744,7
19745,25
19746,95
19747,55
19748,60
19749,60
19750,35
19751,58
19752,95
19753,72
19754,16
19755,77
19756,4
19757,73
19758,24
19759,42
19760,41
19761,72
19762,13
19763,50
19764,87
19765,87
19766,6
19767,77
19768,60
19769,78
19770,9
19771,77
19772,6
19773,53
19774,53
19775,77
19776,4
19777,89
19778,40
19779,7
19780,89
19781,54
19782,74
19783,22
19784,4
19785,4
19786,17
19787,32
19788,76
19789,76
19790,20
19791,38
19792,50
19793,75
19794,88
19795,4
19796,32
19797,76
19798,76
19799,90
19800,55
19801,96
19802,25
19803,4
19804,7
19805,88
19806,25
19807,63
19808,53
19809,87
19810,6
19811,15
19812,82
19813,74
19814,74
19815,77
19816,57
19817,28
19818,53
19819,10
19820,34
19821,77
19822,72
19823,55
19824,84
19825,52
19826,27
19827,41
19828,22
19829,73
19830,72
19831,10
19832,13
19833,79
19834,72
19835,16
19836,33
19837,63
19838,68
19839,24
19840,43
19841,79
19842,29
19843,79
19844,35
19845,60
19846,55
19847,35
19848,70
19849,70
19850,23
19851,70
19852,98
19853,70
19854,60
19855,35
19856,55
19857,87
19858,55
19859,95
19860,29
19861,93
19862,73
19863,5
19864,30
19865,61
19866,63
19867,75
19868,72
19869,16
19870,72
19871,30
19872,95
19873,83
19874,7
19875,83
19876,72
19877,97
19878,79
19879,80
19880,50
19881,72
19882,27
19883,28
19884,77
19885,50
19886,77
19887,89
19888,28
19889,74
19890,36
19891,15
19892,87
19893,6
19894,53
19895,7
19896,40
19897,82
19898,82
19899,40
19900,88
19901,17
19902,76
19903,32
19904,32
19905,4
19906,40
19907,85
19908,50
19909,38
19910,80
19911,76
19912,2
19913,40
19914,50
19915,32
19916,34
19917,97
19918,39
19919,55
19920,40
19921,76
19922,73
19923,40
19924,10
19925,40
19926,54
19927,90
19928,2
19929,53
19930,42
19931,71
19932,15
19933,87
19934,50
19935,10
19936,77
19937,95
19938,28
19939,13
19940,77
19941,71
19942,77
19943,30
19944,85
19945,73
19946,77
19947,72
19948,15
19949,10
19950,13
19951,74
19952,47
19953,45
19954,83
19955,73
19956,16
19957,54
19958,94
19959,55
19960,94
19961,95
19962,43
19963,42
19964,89
19965,83
19966,85
19967,55
19968,60
19969,12
19970,10
19971,73
19972,47
19973,70
19974,70
19975,70
19976,77
19977,70
19978,49
19979,12
19980,35
19981,35
19982,55
19983,60
19984,5
19985,29
19986,95
19987,95
19988,73
19989,55
19990,43
19991,16
19992,25
19993,54
19994,72
19995,80
19996,28
19997,50
19998,15
19999,27
20000,52
20001,10
20002,95
20003,82
20004,63
20005,72
20006,85
20007,74
20008,19
20009,78
20010,22
20011,77
20012,77
20013,96
20014,28
20015,73
20016,87
20017,74
20018,97
20019,53
20020,6
20021,54
20022,43
20023,40
20024,87
20025,87
20026,88
20027,76
20028,94
20029,17
20030,71
20031,32
20032,76
20033,57
20034,42
20035,67
20036,97
20037,76
20038,74
20039,94
20040,57
20041,76
20042,80
20043,14
20044,76
20045,14
20046,76
20047,41
20048,57
20049,87
20050,79
20051,15
20052,1
20053,50
20054,88
20055,62
20056,4
20057,88
20058,97
20059,42
20060,50
20061,11
20062,77
20063,73
20064,18
20065,98
20066,19
20067,61
20068,86
20069,41
20070,100
20071,41
20072,86
20073,10
20074,61
20075,77
20076,46
20077,15
20078,96
20079,101
20080,47
20081,93
20082,2
20083,51
20084,93
20085,92
20086,16
20087,20
20088,51
20089,24
20090,79
20091,34
20092,35
20093,45
20094,99
20095,45
20096,80
20097,25
20098,50
20099,74
20100,80
20101,15
20102,59
20103,74
20104,22
20105,50
20106,98
20107,45
20108,67
20109,67
20110,45
20111,74
20112,25
20113,59
20114,39
20115,22
20116,74
20117,80
20118,80
20119,74
20120,16
20121,89
20122,45
20123,17
20124,45
20125,10
20126,34
20127,69
20128,7
20129,1
20130,1
20131,68
20132,51
20133,18
20134,93
20135,93
20136,96
20137,50
20138,47
20139,45
20140,89
20141,47
20142,46
20143,73
20144,73
20145,61
20146,81
20147,86
20148,86
20149,73
20150,11
20151,73
20152,79
20153,11
20154,86
20155,41
20156,23
20157,50
20158,87
20159,4
20160,88
20161,85
20162,64
20163,62
20164,50
20165,86
20166,3
20167,64
20168,14
20169,76
20170,57
20171,80
20172,76
20173,80
20174,76
20175,57
20176,77
20177,14
20178,32
20179,50
20180,80
20181,57
20182,76
20183,14
20184,57
20185,76
20186,80
20187,50
20188,64
20189,79
20190,71
20191,62
20192,45
20193,85
20194,42
20195,87
20196,71
20197,11
20198,75
20199,50
20200,75
20201,36
20202,50
20203,84
20204,20
20205,81
20206,61
20207,73
20208,30
20209,86
20210,77
20211,77
20212,47
20213,73
20214,10
20215,47
20216,75
20217,96
20218,100
20219,94
20220,50
20221,93
20222,16
20223,88
20224,50
20225,34
20226,47
20227,77
20228,45
20229,80
20230,22
20231,47
20232,50
20233,1
20234,81
20235,74
20236,63
20237,74
20238,57
20239,1
20240,74
20241,50
20242,28
20243,14
20244,15
20245,50
20246,45
20247,72
20248,45
20249,34
20250,73
20251,16
20252,64
20253,20
20254,50
20255,29
20256,39
20257,42
20258,47
20259,47
20260,93
20261,0
20262,46
20263,77
20264,77
20265,73
20266,50
20267,61
20268,82
20269,77
20270,82
20271,73
20272,36
20273,75
20274,77
20275,42
20276,74
20277,75
20278,11
20279,88
20280,0
20281,73
20282,62
20283,64
20284,10
20285,50
20286,82
20287,14
20288,80
20289,34
20290,57
20291,57
20292,80
20293,50
20294,76
20295,14
20296,37
20297,73
20298,50
20299,71
20300,64
20301,76
20302,14
20303,91
20304,47
20305,57
20306,57
20307,50
20308,32
20309,90
20310,88
20311,50
20312,85
20313,45
20314,35
20315,9
20316,62
20317,73
20318,86
20319,2
20320,61
20321,94
20322,100
20323,94
20324,74
20325,41
20326,73
20327,36
20328,81
20329,82
20330,10
20331,23
20332,46
20333,80
20334,20
20335,94
20336,65
20337,94
20338,47
20339,79
20340,93
20341,34
20342,64
20343,16
20344,45
20345,80
20346,80
20347,10
20348,45
20349,45
20350,99
20351,74
20352,4
20353,1
20354,74
20355,82
20356,1
20357,81
20358,74
20359,74
20360,3
20361,99
20362,88
20363,45
20364,10
20365,48
20366,22
20367,80
20368,45
20369,16
20370,69
20371,64
20372,34
20373,93
20374,87
20375,47
20376,31
20377,71
20378,88
20379,85
20380,20
20381,87
20382,23
20383,46
20384,42
20385,36
20386,74
20387,27
20388,96
20389,56
20390,2
20391,42
20392,100
20393,15
20394,93
20395,73
20396,51
20397,65
20398,86
20399,62
20400,9
20401,8
20402,88
20403,85
20404,85
20405,88
20406,80
20407,76
20408,18
20409,57
20410,99
20411,14
20412,76
20413,57
20414,80
20415,76
20416,73
20417,81
20418,64
20419,82
20420,95
20421,71
20422,50
20423,57
20424,76
20425,80
20426,76
20427,80
20428,71
20429,57
20430,76
20431,27
20432,14
20433,85
20434,45
20435,88
20436,85
20437,62
20438,41
20439,88
20440,8
20441,47
20442,10
20443,94
20444,61
20445,73
20446,74
20447,73
20448,91
20449,94
20450,2
20451,89
20452,97
20453,47
20454,23
20455,77
20456,15
20457,84
20458,69
20459,96
20460,94
20461,89
20462,71
20463,65
20464,47
20465,34
20466,77
20467,16
20468,87
20469,10
20470,80
20471,24
20472,80
20473,64
20474,74
20475,44
20476,45
20477,99
20478,45
20479,86
20480,59
20481,88
20482,73
20483,74
20484,96
20485,100
20486,59
20487,74
20488,74
20489,45
20490,97
20491,99
20492,45
20493,80
20494,24
20495,74
20496,89
20497,74
20498,80
20499,16
20500,90
20501,77
20502,7
20503,96
20504,65
20505,23
20506,92
20507,52
20508,96
20509,51
20510,31
20511,46
20512,77
20513,46
20514,23
20515,94
20516,74
20517,11
20518,75
20519,73
20520,95
20521,91
20522,94
20523,81
20524,86
20525,27
20526,22
20527,79
20528,64
20529,8
20530,47
20531,62
20532,85
20533,88
20534,88
20535,87
20536,57
20537,77
20538,80
20539,76
20540,75
20541,76
20542,80
20543,76
20544,57
20545,57
20546,50
20547,71
20548,93
\" target=\"_blank\">Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# download it (will only work for files < 2MB or so)\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"subm.csv\"):  \n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(final_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=classifier.predict_classes(x_val)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for i in range(len(y_val)):\n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_val,p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
